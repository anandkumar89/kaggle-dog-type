{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity('ERROR')\n",
    "module = hub.Module(\"https://tfhub.dev/google/imagenet/resnet_v2_101/feature_vector/1\", trainable=True);\n",
    "height, width = hub.get_expected_image_size(module);\n",
    "shape = (height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.global_variables()\n",
    "# module.variable_map\n",
    "LOG_DIR = '.graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "# resize images in train folder if not in shape\n",
    "def resize(shape=shape):\n",
    "    \n",
    "    originalFolder = 'train'\n",
    "    resizedFolder  = 'resTrain'\n",
    "    \n",
    "    if not os.path.exists(resizedFolder):\n",
    "        os.makedirs(resizedFolder)\n",
    "        counter = 0\n",
    "        # Iterate through resizing and saving\n",
    "        for img in os.listdir('train'):\n",
    "            counter = counter + 1\n",
    "            pic = cv2.imread(\"train/\" + img, cv2.IMREAD_UNCHANGED)\n",
    "            pic = cv2.resize(pic, shape)\n",
    "            cv2.imwrite(resizedFolder + '/' + img, pic)\n",
    "            print(\"resized image : \" + str(shape) + str(counter) + \" : \"+img + \" : \" );\n",
    "    else: \n",
    "        print(\"folder already exists\");\n",
    "        return\n",
    "\n",
    "# resize images to resnet accepted shape\n",
    "resize(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv(\"labels.csv\", delimiter=',', index_col=0)\n",
    "labelOneHot = pd.get_dummies(label.breed)\n",
    "global curr_batch\n",
    "curr_batch = 0\n",
    "\n",
    "'''\n",
    "input batch-size, default = 100\n",
    "uses global variable curr_batch to remember current batch location\n",
    "returns tuple (list of labels, 4-d array->(batch, h, w, c))\n",
    "'''\n",
    "def next_batch(batch_size=100):\n",
    "    global curr_batch\n",
    "    next_batch = True\n",
    "    start = curr_batch*batch_size\n",
    "    end   = (curr_batch+1)*batch_size\n",
    "    print(\"feeding Batch : \" + str(curr_batch))\n",
    "    # Check is it's last batch\n",
    "    if ((curr_batch+1)*batch_size>len(label)):\n",
    "        end = len(file_list)-1\n",
    "        next_batch = False\n",
    "    \n",
    "    batch_list = label.index[start:end]\n",
    "    label_list = labelOneHot[start:end]\n",
    "    batch = []\n",
    "    for img in batch_list: \n",
    "        pic = cv2.imread(\"resTrain/\"+img+\".jpg\", cv2.IMREAD_UNCHANGED)\n",
    "        batch.append(pic)\n",
    "    batch = np.stack(batch, axis=0)\n",
    "    curr_batch = curr_batch + 1\n",
    "\n",
    "    \n",
    "    return next_batch, batch_list, label_list, batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"retrain_layer\"):\n",
    "    images = tf.placeholder(dtype=tf.float32, shape=(None, height, width, 3), name=\"input_images\")\n",
    "    y      = tf.placeholder(dtype=tf.int32, shape=(None, 120), name=\"labels\")\n",
    "\n",
    "    features = module(images)  # Features with shape [batch_size, 2048], last batch may differ in size\n",
    "    dense1 = tf.layers.dense(inputs=features, units=1024, activation=tf.nn.relu, name=\"dense_1\")\n",
    "    logits = tf.layers.dense(inputs=dense1, units=120, name=\"dense_2\")\n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax\")\n",
    "    }\n",
    "    xent = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=y, logits=logits))\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate=0.01) \\\n",
    "                    .minimize(loss=xent, global_step=tf.train.get_global_step())\n",
    "\n",
    "    eval_metric = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=y, predictions=predictions[\"probabilities\"])}\n",
    "\n",
    "    tf.summary.scalar('cross_entropy', xent)\n",
    "    tf.summary.scalar('accuracy', eval_metric[\"accuracy\"][0])\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    tensors_to_log = {\"probabilities\":\"accuracy\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=10)\n",
    "\n",
    "    summ = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feeding Batch : 0\n",
      "training accuracy : 0.0\n",
      "feeding Batch : 1\n",
      "training accuracy : 0.98333335\n",
      "feeding Batch : 2\n",
      "training accuracy : 0.49166667\n",
      "feeding Batch : 3\n",
      "training accuracy : 0.32777777\n",
      "feeding Batch : 4\n",
      "training accuracy : 0.24583334\n",
      "feeding Batch : 5\n",
      "training accuracy : 0.19666667\n",
      "feeding Batch : 6\n",
      "training accuracy : 0.16388889\n",
      "feeding Batch : 7\n",
      "training accuracy : 0.1404762\n",
      "feeding Batch : 8\n",
      "training accuracy : 0.12291667\n",
      "feeding Batch : 9\n",
      "training accuracy : 0.10925926\n",
      "feeding Batch : 10\n",
      "training accuracy : 0.09833334\n",
      "feeding Batch : 11\n",
      "training accuracy : 0.089393936\n",
      "feeding Batch : 12\n",
      "training accuracy : 0.08194444\n",
      "feeding Batch : 13\n",
      "training accuracy : 0.07564103\n",
      "feeding Batch : 14\n",
      "training accuracy : 0.0702381\n",
      "feeding Batch : 15\n",
      "training accuracy : 0.06555556\n",
      "feeding Batch : 16\n",
      "training accuracy : 0.061458334\n",
      "feeding Batch : 17\n",
      "training accuracy : 0.057843138\n",
      "feeding Batch : 18\n",
      "training accuracy : 0.05462963\n",
      "feeding Batch : 19\n",
      "training accuracy : 0.051754385\n",
      "feeding Batch : 20\n",
      "training accuracy : 0.04916667\n",
      "feeding Batch : 21\n",
      "training accuracy : 0.046825398\n",
      "feeding Batch : 22\n",
      "training accuracy : 0.044696968\n",
      "feeding Batch : 23\n",
      "training accuracy : 0.042753622\n",
      "feeding Batch : 24\n",
      "training accuracy : 0.04097222\n",
      "feeding Batch : 25\n",
      "training accuracy : 0.039333332\n",
      "feeding Batch : 26\n",
      "training accuracy : 0.037820514\n",
      "feeding Batch : 27\n",
      "training accuracy : 0.036419753\n",
      "feeding Batch : 28\n",
      "training accuracy : 0.03511905\n",
      "feeding Batch : 29\n",
      "training accuracy : 0.033908047\n",
      "feeding Batch : 30\n",
      "training accuracy : 0.03277778\n",
      "feeding Batch : 31\n",
      "training accuracy : 0.03172043\n",
      "feeding Batch : 32\n",
      "training accuracy : 0.030729167\n",
      "feeding Batch : 33\n",
      "training accuracy : 0.02979798\n",
      "feeding Batch : 34\n",
      "training accuracy : 0.028921569\n",
      "feeding Batch : 35\n",
      "training accuracy : 0.028095238\n",
      "feeding Batch : 36\n",
      "training accuracy : 0.027314816\n",
      "feeding Batch : 37\n",
      "training accuracy : 0.026576577\n",
      "feeding Batch : 38\n",
      "training accuracy : 0.025877193\n",
      "feeding Batch : 39\n",
      "training accuracy : 0.025213676\n",
      "feeding Batch : 40\n",
      "training accuracy : 0.024583334\n",
      "feeding Batch : 41\n",
      "training accuracy : 0.02398374\n",
      "feeding Batch : 42\n",
      "training accuracy : 0.023412699\n",
      "feeding Batch : 43\n",
      "training accuracy : 0.022868218\n",
      "feeding Batch : 44\n",
      "training accuracy : 0.022348484\n",
      "feeding Batch : 45\n"
     ]
    }
   ],
   "source": [
    "batchNext = True\n",
    "curr_batch = 0\n",
    "counter = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_g = tf.global_variables_initializer()\n",
    "    init_l = tf.local_variables_initializer()\n",
    "    writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "    saver  = tf.train.Saver()\n",
    "    sess.run(init_g)\n",
    "    sess.run(init_l)\n",
    "\n",
    "    while(batchNext):\n",
    "        batchNext, imglist, batch_label, image = next_batch(10)  # A batch of images with shape [batch_size, height, width, 3].\n",
    "\n",
    "        [train_accuracy, s] = sess.run([eval_metric[\"accuracy\"], summ], feed_dict={images: image, y: batch_label})\n",
    "        writer.add_summary(s, counter)\n",
    "        print(\"training accuracy : \" + str(train_accuracy[0]))\n",
    "        if counter % 20 == 0:\n",
    "    #         sess.run(assignment, feed_dict={x: , y: mnist.test.labels[:1024]})\n",
    "            saver.save(sess, os.path.join(LOG_DIR, \"kaggle-dog-identification.ckpt\"), counter)\n",
    "        sess.run(train_step, feed_dict={images: image, y: batch_label})\n",
    "        counter = counter+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_summary = tf.summary.merge_all()\n",
    "# writer = tf.summary.FileWriter(LOG_DIR, tf.get_default_graph())\n",
    "\n",
    "# init_g = tf.global_variables_initializer()\n",
    "# init_l = tf.local_variables_initializer()\n",
    "# sess = tf.Session()\n",
    "# sess.run(init_g)\n",
    "# sess.run(init_l)\n",
    "# sess.run(optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
