{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags\n",
    "LOG_DIR = \".graph_scratch1\"\n",
    "TRAIN_DIR = 'resTrain/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(force=False):\n",
    "    if not(force):\n",
    "        # check if transformed image directory exits\n",
    "        # read and randomly sample from directory\n",
    "        pass\n",
    "    else:\n",
    "        # overwrite image directory \n",
    "        # perform all image transformation\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv(\"labels.csv\", delimiter=',', index_col=0) # 120 labels\n",
    "labelOneHot = pd.get_dummies(label.breed) # 120 labels\n",
    "\n",
    "# train and validation set\n",
    "val_set = labelOneHot.sample(n=222, replace=False)\n",
    "labelOneHot  = labelOneHot.drop(labels=val_set.index, axis=0)\n",
    "\n",
    "global curr_batch  # flag to track current batch being fed in each epoch\n",
    "curr_batch = 0     # first initialization, re-initialize with caution\n",
    "\n",
    "'''\n",
    "input batch-size, default = 100\n",
    "uses global variable curr_batch to remember current batch location\n",
    "returns tuple (flag for next batch, list of files, list of labels, 4-d array->(batch, h, w, c))\n",
    "'''\n",
    "def next_batch(batch_size=25, random=False):\n",
    "    next_batch = True\n",
    "    if random:\n",
    "        label_list = val_set.sample(n=batch_size, replace=False)\n",
    "        batch_list = label_list.index\n",
    "    else:\n",
    "        global curr_batch\n",
    "        start = curr_batch*batch_size\n",
    "        end   = (curr_batch+1)*batch_size\n",
    "        # print(\"feeding Batch : \" + str(curr_batch))\n",
    "        # Check is it's last batch\n",
    "        if ((curr_batch+1)*batch_size>len(labelOneHot)):\n",
    "            end = len(labelOneHot)-1\n",
    "            next_batch = False\n",
    "        label_list = labelOneHot[start:end]\n",
    "        batch_list = label_list.index\n",
    "\n",
    "    \n",
    "    batch = []\n",
    "    for img in batch_list:\n",
    "        pic = cv2.imread(TRAIN_DIR+img+\".jpg\", cv2.IMREAD_UNCHANGED)\n",
    "        batch.append(pic)\n",
    "    batch = np.stack(batch, axis=0)\n",
    "    if not(random):\n",
    "        curr_batch = curr_batch + 1\n",
    "    \n",
    "    return next_batch, batch_list, np.argmax(label_list.values, axis=1), batch\n",
    "\n",
    "'''\n",
    "input  : takes an iterator ( of numbers ), as list, tuple, range\n",
    "return : product of all numbers in iterator\n",
    "'''\n",
    "reduce_mul = lambda list_ : reduce(lambda x,y: x*y, list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Graph Definition\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x_image = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name=\"X\")\n",
    "y       = tf.placeholder(tf.int32, shape=(None,), name=\"Y\")\n",
    "is_training = tf.placeholder(tf.bool, name=\"trainFlag\")\n",
    "\n",
    "c1 = tf.layers.conv2d(x_image, filters=8, kernel_size=[5,5], padding=\"SAME\", activation=tf.nn.relu, name=\"conv1\")\n",
    "p1 = tf.layers.max_pooling2d(c1, pool_size=[2,2], strides=2, name=\"pool1\")\n",
    "\n",
    "\n",
    "c2 = tf.layers.conv2d(p1, filters=16, kernel_size=[5,5], padding=\"SAME\", activation=tf.nn.relu, name=\"conv2\")\n",
    "p2 = tf.layers.max_pooling2d(c2, pool_size=[2,2], strides=2, name=\"pool2\")\n",
    "\n",
    "\n",
    "# c3 = tf.layers.conv2d(p2, filters=32, kernel_size=[3,3], padding=\"SAME\", activation=tf.nn.relu, name=\"conv3\")\n",
    "# p3 = tf.layers.max_pooling2d(c3, pool_size=[4,4], strides=4, name=\"pool3\")\n",
    "\n",
    "p3 = p2\n",
    "\n",
    "# Dense Layer\n",
    "ndim = reduce_mul(p3.get_shape().as_list()[1:])\n",
    "p3_flat = tf.reshape(p3, [-1, ndim])\n",
    "dense = tf.layers.dense(inputs=p3_flat, units=3136, activation=tf.nn.relu, name=\"fc1\")\n",
    "dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=is_training, name=\"dropout\") # Set this flag to false while making prediction\n",
    "\n",
    "# Logits Layer\n",
    "logits = tf.layers.dense(inputs=dropout, units=120, name=\"fc2\")\n",
    "\n",
    "predictions = {\n",
    "  \"classes\": tf.argmax(input=logits, axis=1),\n",
    "  \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "}\n",
    "\n",
    "# Calculate Loss\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
    "xent = tf.reduce_mean(loss)\n",
    "\n",
    "# Configure the Training \n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=0.01)\n",
    "train_step = optimizer.minimize(\n",
    "    loss=xent,\n",
    "    global_step=tf.train.get_global_step())\n",
    "\n",
    "# Add evaluation metrics\n",
    "eval_metric = {\n",
    "    \"accuracy\": tf.metrics.accuracy(labels=y, predictions=predictions[\"classes\"])}\n",
    "\n",
    "\n",
    "tf.summary.scalar('cross_entropy', xent, )\n",
    "tf.summary.scalar('accuracy', eval_metric[\"accuracy\"][0])\n",
    "summ = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0, Iteration:   0, training accuracy : 0.00000\n",
      "Epoch:  0, Iteration:   1, training accuracy : 0.01000\n",
      "Epoch:  0, Iteration:   2, training accuracy : 0.00500\n",
      "Epoch:  0, Iteration:   3, training accuracy : 0.00333\n",
      "Epoch:  0, Iteration:   4, training accuracy : 0.00250\n",
      "Epoch:  0, Iteration:   5, training accuracy : 0.00600\n",
      "Epoch:  0, Iteration:   6, training accuracy : 0.00500\n",
      "Epoch:  0, Iteration:   7, training accuracy : 0.00429\n",
      "Epoch:  0, Iteration:   8, training accuracy : 0.00625\n",
      "Epoch:  0, Iteration:   9, training accuracy : 0.00667\n",
      "Epoch:  0, Iteration:  10, training accuracy : 0.00600\n",
      "Epoch:  0, Iteration:  11, training accuracy : 0.00545\n",
      "Epoch:  0, Iteration:  12, training accuracy : 0.00500\n",
      "Epoch:  0, Iteration:  13, training accuracy : 0.00462\n",
      "Epoch:  0, Iteration:  14, training accuracy : 0.00571\n",
      "Epoch:  0, Iteration:  15, training accuracy : 0.00733\n",
      "Epoch:  0, Iteration:  16, training accuracy : 0.00687\n",
      "Epoch:  0, Iteration:  17, training accuracy : 0.00706\n",
      "Epoch:  0, Iteration:  18, training accuracy : 0.00722\n",
      "Epoch:  0, Iteration:  19, training accuracy : 0.00737\n",
      "Epoch:  0, Iteration:  20, training accuracy : 0.00700\n",
      "Epoch:  0, Iteration:  21, training accuracy : 0.00667\n",
      "Epoch:  0, Iteration:  22, training accuracy : 0.00682\n",
      "Epoch:  0, Iteration:  23, training accuracy : 0.00696\n",
      "Epoch:  0, Iteration:  24, training accuracy : 0.00708\n",
      "Epoch:  0, Iteration:  25, training accuracy : 0.00720\n",
      "Epoch:  0, Iteration:  26, training accuracy : 0.00692\n",
      "Epoch:  0, Iteration:  27, training accuracy : 0.00741\n",
      "Epoch:  0, Iteration:  28, training accuracy : 0.00786\n",
      "Epoch:  0, Iteration:  29, training accuracy : 0.00759\n",
      "Epoch:  0, Iteration:  30, training accuracy : 0.00800\n",
      "Epoch:  0, Iteration:  31, training accuracy : 0.00774\n",
      "Epoch:  0, Iteration:  32, training accuracy : 0.00750\n",
      "Epoch:  0, Iteration:  33, training accuracy : 0.00758\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "batchNext = True\n",
    "curr_batch = 0\n",
    "counter = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_g = tf.global_variables_initializer()\n",
    "    init_l = tf.local_variables_initializer()\n",
    "    writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "    saver  = tf.train.Saver()\n",
    "    sess.run(init_g)\n",
    "    sess.run(init_l)\n",
    "    saver.recover_last_checkpoints(LOG_DIR)\n",
    "    for epoch in range(2):\n",
    "        curr_batch = 0\n",
    "        while(batchNext):\n",
    "            batchNext, _, batch_label, image = next_batch(100)  # A batch of images with shape [batch_size, height, width, 3].\n",
    "#             _, _, batch_label_cv, image_cv = next_batch(500, True) # randomly sample images for cross-validation [batch_size, height, width, 3].\n",
    "\n",
    "            [train_accuracy, s] = sess.run([eval_metric[\"accuracy\"], summ], feed_dict={x_image: image, y: batch_label, is_training:False})\n",
    "#             [train_accuracy_cv, s_cv] = sess.run([eval_metric[\"accuracy\"], summ], feed_dict={x_image: image_cv, y: batch_label_cv, is_training:False})\n",
    "            writer.add_summary(s, counter)\n",
    "#             writer.add_summary(s_cv, counter)\n",
    "#             print(\"Epoch: %2d, Iteration: %3d, training accuracy : %6.5f , cv_accuracy: %6.5f\"%(epoch, counter, train_accuracy[0], train_accuracy_cv[0]))\n",
    "            print(\"Epoch: %2d, Iteration: %3d, training accuracy : %6.5f\"%(epoch, counter, train_accuracy[0]))\n",
    "            if counter % 20 == 0:\n",
    "        #         sess.run(assignment, feed_dict={x: , y: mnist.test.labels[:1024]})\n",
    "                saver.save(sess, os.path.join(LOG_DIR, \"kaggle-dog-identification-cnn.ckpt\"), counter)\n",
    "            sess.run(train_step, feed_dict={x_image: image, y: batch_label, is_training:True})\n",
    "            counter = counter+1      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     init_g = tf.global_variables_initializer()\n",
    "#     init_l = tf.local_variables_initializer()\n",
    "#     writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "#     saver  = tf.train.Saver()\n",
    "#     sess.run(init_g)\n",
    "#     sess.run(init_l)\n",
    "#     pred = sess.run(predictions, feed_dict={x_image:d, y:c, is_training:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Image Transformation Definitions '''\n",
    "'''\n",
    "randomly crop image\n",
    "set kee_dim true to keep input and out put dimensions same\n",
    "cropped height and width fraction\n",
    "'''\n",
    "def random_crop(input, h_frac=0.6, w_frac=0.6, keep_dim=True):\n",
    "    height, width, _ = input.shape\n",
    "    h, w = int(h_frac*height), int(w_frac*width)\n",
    "    y, x = np.random.randint(0, height-h), np.random.randint(0, width-w)\n",
    "    if keep_dim:\n",
    "        return cv2.resize(input[x:x+w, y:y+h, :], (height, width), interpolation=cv2.INTER_CUBIC)\n",
    "    else:\n",
    "        return input[x:x+w, y:y+h, :]\n",
    "\n",
    "'''\n",
    "Performs gaussian or median blur of random strength\n",
    "upper limit of blur strength can be passes as parameter\n",
    "'''\n",
    "def random_blur(input, max_strength=0.3):\n",
    "    h, w, _ = input.shape\n",
    "    rand = np.random.randint(0, max_strength*h)\n",
    "    if rand%2==0:\n",
    "        max_strength = max_strength/2\n",
    "        a, b = np.random.randint(1, int(max_strength*h)), np.random.randint(1, int(max_strength*w))\n",
    "        a, b = 2*a+1, 2*b+1 \n",
    "        return cv2.GaussianBlur(input,(a, b),0)\n",
    "    else:\n",
    "        rand = 2*int(rand/4)+1\n",
    "        print(\"here: \"+str(rand))\n",
    "        return cv2.medianBlur(input,rand)\n",
    "\n",
    "'''\n",
    "randomly rotate the image about center with scale factor of 1.1\n",
    "'''\n",
    "def random_rotate(input):\n",
    "    rows, cols, _ = input.shape\n",
    "    theta = np.random.randint(0, 360)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),theta,1.1)\n",
    "    return cv2.warpAffine(input,M,(cols,rows))\n",
    "\n",
    "def random_noise(input, strength=None):\n",
    "    a, b, c = input.shape\n",
    "    if strength==None:\n",
    "        strength = np.random.randint(0, 50)\n",
    "    noise = np.random.randn(a, b, c)\n",
    "    out = input+strength*noise\n",
    "    a = np.max(out); b = min(0, np.min(out))\n",
    "    return np.uint8(254/(a-b)*(out-b))\n",
    "     \n",
    "def random_skew():\n",
    "\n",
    "    pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "    pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    "\n",
    "    M = cv2.getAffineTransform(pts1,pts2)\n",
    "\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
